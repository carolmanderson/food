{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'correct_BIO_encodings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2e5b5e01b32c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfood_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokens_to_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_BIO_encodings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'correct_BIO_encodings'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from food_tools.training.dataset_utils import tokens_to_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_displacy(tokens, labels):\n",
    "    text = \"\"\n",
    "    start = 0\n",
    "    ents = []\n",
    "    curr_label = \"\"\n",
    "    new_ent = {}\n",
    "    for token, label in zip(tokens, labels):\n",
    "        text += token + \" \"\n",
    "        end = start + len(token)\n",
    "        if label.startswith(\"B-\"):\n",
    "            if new_ent:\n",
    "                ents.append(new_ent)\n",
    "            curr_label = label[2:]\n",
    "            new_ent = {\"start\": start, \"end\": end,\n",
    "                       \"label\": curr_label}\n",
    "        elif label.startswith(\"I-\"):\n",
    "            assert label[2:] == curr_label\n",
    "            new_ent['end'] = end\n",
    "        elif label == \"O\":\n",
    "            if new_ent:\n",
    "                ents.append(new_ent)\n",
    "                new_ent = {}\n",
    "        else:\n",
    "            raise Exception(\"Found non-BIO label {}!\".format(label))\n",
    "        start += len(token) + 1\n",
    "    if new_ent:\n",
    "        ents.append(new_ent)\n",
    "    doc = {\"text\": text,\n",
    "           \"ents\": ents,\n",
    "           \"title\": None}\n",
    "    return doc\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    https://github.com/tensorflow/tensorflow/issues/14356\n",
    "    https://github.com/tensorflow/tensorflow/issues/28287\n",
    "    \"\"\"\n",
    "    session = tf.Session(graph=tf.Graph())\n",
    "    with session.graph.as_default():\n",
    "        K.set_session(session)\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "        loaded_model.summary()\n",
    "    return loaded_model, session\n",
    "\n",
    "\n",
    "def load_mappings(filepath):\n",
    "    return pickle.load(open(filepath, \"rb\"))\n",
    "\n",
    "\n",
    "def load_sentencizer_and_tokenizer():\n",
    "    nlp = English()\n",
    "    sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "    nlp.add_pipe(sentencizer)\n",
    "    tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "    return nlp, tokenizer\n",
    "\n",
    "\n",
    "def form_matrix(tokens):\n",
    "    tokens = np.expand_dims(tokens, axis=0)\n",
    "    return np.array(tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0503 12:20:41.921288 140736447558592 deprecation.py:506] From /Users/Carol/anaconda/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0503 12:20:41.933290 140736447558592 deprecation.py:506] From /Users/Carol/anaconda/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0503 12:20:41.934798 140736447558592 deprecation.py:506] From /Users/Carol/anaconda/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0503 12:20:41.937363 140736447558592 deprecation.py:506] From /Users/Carol/anaconda/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0503 12:20:41.975152 140736447558592 deprecation.py:506] From /Users/Carol/anaconda/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0503 12:20:43.754074 140736447558592 deprecation.py:323] From /Users/Carol/anaconda/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "token_input (InputLayer)     [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "word_embeddings (Embedding)  (None, None, 100)         40000500  \n",
      "_________________________________________________________________\n",
      "BiLSTM (Bidirectional)       (None, None, 200)         160800    \n",
      "_________________________________________________________________\n",
      "output_softmax (TimeDistribu (None, None, 3)           603       \n",
      "=================================================================\n",
      "Total params: 40,161,903\n",
      "Trainable params: 40,161,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model = \"/Users/Carol/Google Drive/nlp_data/output/20200503_16_50_50/20200503_16_50_50_food_ner_epoch_3_dev_f1_0.9867637173043644.h5\"\n",
    "\n",
    "saved_mappings = \"/Users/Carol/Google Drive/nlp_data/output/20200503_16_50_50/20200503_16_50_50_food_ner_mappings.pkl\"\n",
    "\n",
    "model, session = load_model(saved_model)\n",
    "mappings = load_mappings(saved_mappings)\n",
    "index_to_label = {v: k for k, v in mappings['label_to_index'].items()}\n",
    "token_to_index = mappings['token_to_index']\n",
    "sentencizer, tokenizer  = load_sentencizer_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"Heat garlic and rosemary with oil. Drizzle oil over dip and serve with \" \\\n",
    "                    \"vegetables.\"\n",
    "text = \"Combine pineapple, banana, cream of coconut, rolled \" \\\n",
    "                \"oats, quick-cooking oats, baking powder, mint, \" \\\n",
    "                \"chia seeds, and poppy seeds in a blender; blend until \" \\\n",
    "                \"smooth. Pour into 2 mugs.\"\n",
    "\n",
    "\n",
    "\n",
    "sents = sentencizer(text)\n",
    "all_tokens = []\n",
    "for sent in sents.sents:\n",
    "    tokens = tokenizer(sent.text)\n",
    "    all_tokens.append([t.text for t in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doc = None   # collects results from all sentences\n",
    "with session.graph.as_default():\n",
    "    K.set_session(session)\n",
    "    for tokens in all_tokens:\n",
    "        token_indices = tokens_to_indices(tokens, token_to_index)\n",
    "        preds = model.predict([tokens_to_indices(tokens, token_to_index)])\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "        labels = [index_to_label[ind[0]] for ind in preds]\n",
    "        labels = correct_BIO_encodings(labels)\n",
    "        doc = output_to_displacy(tokens, labels)\n",
    "        if not final_doc:  # first sentence\n",
    "            final_doc = doc\n",
    "            continue\n",
    "        shift = len(final_doc['text'])\n",
    "        for ent in doc['ents']:\n",
    "            ent['start'] += shift\n",
    "            ent['end'] += shift\n",
    "            final_doc['ents'].append(ent)\n",
    "        final_doc['text'] += doc['text']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Combine \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pineapple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    banana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cream\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " of \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    coconut\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , rolled \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    oats\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , quick \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    -\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " cooking \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    oats\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , baking \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    powder\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mint\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chia seeds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , and \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    poppy seeds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " in a blender ; blend until smooth . Pour into 2 mugs . </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {\"FOOD\": \"#87CEEB\"}\n",
    "options = {\"ents\": [\"FOOD\"], \"colors\": colors}\n",
    "displacy.render(final_doc, style=\"ent\", options={\"colors\":colors},\n",
    "                       manual=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get examples from dev set\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "from food_tools.training.dataset_utils import read_conll_file, compile_vocabulary, make_label_map, get_token_embeddings, examples_to_indices, tokens_to_indices\n",
    "from food_tools.training.train_utils import get_current_time, form_ner_train_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/Carol/Google Drive/\"\n",
    "dev_file = os.path.join(base_path, \"nlp_data/recipe_data/20200523_food_gold_test.conll\")\n",
    "dev_dataset = read_conll_file(dev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = random.sample(dev_dataset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Preheat', 'O'],\n",
       "  ['oven', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['375', 'O'],\n",
       "  ['°', 'O'],\n",
       "  ['F', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Place', 'O'],\n",
       "  ['apples', 'B-FOOD'],\n",
       "  ['on', 'O'],\n",
       "  ['large', 'O'],\n",
       "  ['rimmed', 'O'],\n",
       "  ['baking', 'O'],\n",
       "  ['sheet', 'O'],\n",
       "  [';', 'O'],\n",
       "  ['toss', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['3', 'O'],\n",
       "  ['tablespoons', 'O'],\n",
       "  ['sugar', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['2', 'O'],\n",
       "  ['tablespoons', 'O'],\n",
       "  ['butter', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['lemon', 'B-FOOD'],\n",
       "  ['juice', 'I-FOOD'],\n",
       "  ['.', 'O'],\n",
       "  ['Roast', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['apples', 'B-FOOD'],\n",
       "  ['are', 'O'],\n",
       "  ['tender', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['stirring', 'O'],\n",
       "  ['occasionally', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['45', 'O'],\n",
       "  ['minutes', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Transfer', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['large', 'O'],\n",
       "  ['bowl', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Stir', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['cherries', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['brown', 'B-FOOD'],\n",
       "  ['sugar', 'I-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['vanilla', 'B-FOOD'],\n",
       "  ['.', 'O'],\n",
       "  ['Cool', 'O'],\n",
       "  ['completely', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Heat', 'O'],\n",
       "  ['ghee', 'B-FOOD'],\n",
       "  ['in', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['large', 'O'],\n",
       "  ['Dutch', 'O'],\n",
       "  ['oven', 'O'],\n",
       "  ['over', 'O'],\n",
       "  ['medium', 'O'],\n",
       "  ['heat', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Season', 'O'],\n",
       "  ['chicken', 'B-FOOD'],\n",
       "  ['with', 'O'],\n",
       "  ['salt', 'B-FOOD'],\n",
       "  ['and', 'O'],\n",
       "  ['pepper', 'B-FOOD'],\n",
       "  ['.', 'O'],\n",
       "  ['Working', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['batches', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['cook', 'O'],\n",
       "  ['chicken', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['skin', 'O'],\n",
       "  ['side', 'O'],\n",
       "  ['down', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['golden', 'O'],\n",
       "  ['brown', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['turn', 'O'],\n",
       "  [')', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['8–10', 'O'],\n",
       "  ['minutes', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Transfer', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['plate', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['6', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Chop', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['asparagus', 'B-FOOD'],\n",
       "  ['and', 'O'],\n",
       "  ['leeks', 'B-FOOD'],\n",
       "  ['into', 'O'],\n",
       "  ['1-inch', 'O'],\n",
       "  ['pieces', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Line', 'O'],\n",
       "  ['baking', 'O'],\n",
       "  ['sheet', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['paper', 'O'],\n",
       "  ['towel', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Heat', 'O'],\n",
       "  ['oil', 'B-FOOD'],\n",
       "  ['in', 'O'],\n",
       "  ['heavy', 'O'],\n",
       "  ['large', 'O'],\n",
       "  ['skillet', 'O'],\n",
       "  ['over', 'O'],\n",
       "  ['medium', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['high', 'O'],\n",
       "  ['heat', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Measure', 'O'],\n",
       "  ['scant', 'O'],\n",
       "  ['1/4', 'O'],\n",
       "  ['cupful', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['mixture', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['shape', 'O'],\n",
       "  ['into', 'O'],\n",
       "  ['ball', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['add', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['skillet', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Using', 'O'],\n",
       "  ['spatula', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['gently', 'O'],\n",
       "  ['flatten', 'O'],\n",
       "  ['ball', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['1/3-inch', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['thick', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['3-inch', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['diameter', 'O'],\n",
       "  ['pancake', 'B-FOOD'],\n",
       "  ['.', 'O'],\n",
       "  ['Repeat', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['forming', 'O'],\n",
       "  ['3', 'O'],\n",
       "  ['more', 'O'],\n",
       "  ['pancakes', 'B-FOOD'],\n",
       "  ['.', 'O'],\n",
       "  ['Fry', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['golden', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['3', 'O'],\n",
       "  ['minutes', 'O'],\n",
       "  ['per', 'O'],\n",
       "  ['side', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Transfer', 'O'],\n",
       "  ['pancakes', 'B-FOOD'],\n",
       "  ['to', 'O'],\n",
       "  ['prepared', 'O'],\n",
       "  ['baking', 'O'],\n",
       "  ['sheet', 'O'],\n",
       "  [';', 'O'],\n",
       "  ['keep', 'O'],\n",
       "  ['warm', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['oven', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Repeat', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['remaining', 'O'],\n",
       "  ['mixture', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['total', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['8', 'O'],\n",
       "  ['pancakes', 'B-FOOD'],\n",
       "  ['.', 'O']],\n",
       " [['Heat', 'O'],\n",
       "  ['1/2', 'O'],\n",
       "  ['cup', 'O'],\n",
       "  ['oil', 'B-FOOD'],\n",
       "  ['in', 'O'],\n",
       "  ['heavy', 'O'],\n",
       "  ['large', 'O'],\n",
       "  ['skillet', 'O'],\n",
       "  ['over', 'O'],\n",
       "  ['medium', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['high', 'O'],\n",
       "  ['heat', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Working', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['batches', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['fry', 'O'],\n",
       "  ['crab', 'B-FOOD'],\n",
       "  ['cakes', 'I-FOOD'],\n",
       "  ['until', 'O'],\n",
       "  ['brown', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['adding', 'O'],\n",
       "  ['more', 'B-FOOD'],\n",
       "  ['oil', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['skillet', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['needed', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['4', 'O'],\n",
       "  ['minutes', 'O'],\n",
       "  ['per', 'O'],\n",
       "  ['side', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Transfer', 'O'],\n",
       "  ['2', 'O'],\n",
       "  ['crab', 'B-FOOD'],\n",
       "  ['cakes', 'I-FOOD'],\n",
       "  ['to', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['12', 'O'],\n",
       "  ['plates', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Serve', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['passing', 'O'],\n",
       "  ['caper', 'B-FOOD'],\n",
       "  ['sauce', 'I-FOOD'],\n",
       "  ['alongside', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Spoon', 'O'],\n",
       "  ['half', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['mousse', 'B-FOOD'],\n",
       "  ['into', 'O'],\n",
       "  ['mold', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['soufflé', 'O'],\n",
       "  ['dish', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['smooth', 'O'],\n",
       "  ['top', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Spoon', 'O'],\n",
       "  ['roe', 'B-FOOD'],\n",
       "  ['evenly', 'O'],\n",
       "  ['over', 'O'],\n",
       "  ['mousse', 'B-FOOD'],\n",
       "  ['(', 'O'],\n",
       "  ['roe', 'B-FOOD'],\n",
       "  ['will', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['cover', 'O'],\n",
       "  ['mousse', 'B-FOOD'],\n",
       "  ['completely', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['sprinkle', 'O'],\n",
       "  ['evenly', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['dill', 'B-FOOD'],\n",
       "  ['.', 'O'],\n",
       "  ['Spoon', 'O'],\n",
       "  ['remaining', 'O'],\n",
       "  ['mousse', 'B-FOOD'],\n",
       "  ['over', 'O'],\n",
       "  ['dill', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['spreading', 'O'],\n",
       "  ['mousse', 'B-FOOD'],\n",
       "  ['evenly', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['being', 'O'],\n",
       "  ['careful', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['disturb', 'O'],\n",
       "  ['roe', 'B-FOOD'],\n",
       "  ['and', 'O'],\n",
       "  ['dill', 'B-FOOD'],\n",
       "  [')', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['gently', 'O'],\n",
       "  ['smooth', 'O'],\n",
       "  ['surface', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Chill', 'O'],\n",
       "  ['mousse', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['covered', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['least', 'O'],\n",
       "  ['12', 'O'],\n",
       "  ['hours', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['up', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['2', 'O'],\n",
       "  ['days', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Combine', 'O'],\n",
       "  ['1/4', 'O'],\n",
       "  ['cup', 'O'],\n",
       "  ['water', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['ginger', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['sugar', 'B-FOOD'],\n",
       "  ['in', 'O'],\n",
       "  ['heavy', 'O'],\n",
       "  ['small', 'O'],\n",
       "  ['saucepan', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Stir', 'O'],\n",
       "  ['over', 'O'],\n",
       "  ['medium', 'O'],\n",
       "  ['heat', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['sugar', 'B-FOOD'],\n",
       "  ['dissolves', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Simmer', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['mixture', 'B-FOOD'],\n",
       "  ['is', 'O'],\n",
       "  ['syrupy', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['5', 'O'],\n",
       "  ['minutes', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Cool', 'O'],\n",
       "  ['completely', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Using', 'O'],\n",
       "  ['electric', 'O'],\n",
       "  ['mixer', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['beat', 'O'],\n",
       "  ['cream', 'B-FOOD'],\n",
       "  ['in', 'O'],\n",
       "  ['medium', 'O'],\n",
       "  ['bowl', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['peaks', 'O'],\n",
       "  ['form', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Fold', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['ginger', 'B-FOOD'],\n",
       "  ['mixture', 'I-FOOD'],\n",
       "  ['.', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['Can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['made', 'O'],\n",
       "  ['4', 'O'],\n",
       "  ['hours', 'O'],\n",
       "  ['ahead', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Cover', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['chill', 'O'],\n",
       "  ['.', 'O'],\n",
       "  [')', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['cocktail', 'O'],\n",
       "  ['shaker', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['combine', 'O'],\n",
       "  ['gin', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['Chambord', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['cranberry', 'B-FOOD'],\n",
       "  ['juice', 'I-FOOD'],\n",
       "  ['and', 'O'],\n",
       "  ['egg', 'B-FOOD'],\n",
       "  ['white', 'I-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['shake', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['drink', 'O'],\n",
       "  ['vigorously', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['strain', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['into', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['chilled', 'O'],\n",
       "  ['cocktail', 'O'],\n",
       "  ['glass', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Keep', 'O'],\n",
       "  ['refrigerated', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['all', 'O'],\n",
       "  ['times', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['You', 'O'],\n",
       "  ['may', 'O'],\n",
       "  ['prepare', 'O'],\n",
       "  ['these', 'O'],\n",
       "  ['custards', 'B-FOOD'],\n",
       "  ['a', 'O'],\n",
       "  ['day', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['two', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['advance', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['but', 'O'],\n",
       "  ['do', 'O'],\n",
       "  [\"n't\", 'O'],\n",
       "  ['keep', 'O'],\n",
       "  ['them', 'O'],\n",
       "  ['more', 'O'],\n",
       "  ['than', 'O'],\n",
       "  ['3', 'O'],\n",
       "  ['days', 'O'],\n",
       "  ['total', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Add', 'O'],\n",
       "  ['potatoes', 'B-FOOD'],\n",
       "  ['to', 'O'],\n",
       "  ['pot', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['cook', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['partially', 'O'],\n",
       "  ['covered', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['potatoes', 'B-FOOD'],\n",
       "  ['are', 'O'],\n",
       "  ['fork', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['tender', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['chicken', 'B-FOOD'],\n",
       "  ['is', 'O'],\n",
       "  ['falling', 'O'],\n",
       "  ['off', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['bone', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['liquid', 'B-FOOD'],\n",
       "  ['is', 'O'],\n",
       "  ['thick', 'O'],\n",
       "  ['enough', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['coat', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['spoon', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['30–45', 'O'],\n",
       "  ['minutes', 'O'],\n",
       "  ['.', 'O'],\n",
       "  ['Remove', 'O'],\n",
       "  ['skin', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['bones', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['chicken', 'B-FOOD'],\n",
       "  [',', 'O'],\n",
       "  ['if', 'O'],\n",
       "  ['desired', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['return', 'O'],\n",
       "  ['meat', 'B-FOOD'],\n",
       "  ['to', 'O'],\n",
       "  ['pot', 'O'],\n",
       "  [';', 'O'],\n",
       "  ['season', 'O'],\n",
       "  ['stew', 'B-FOOD'],\n",
       "  ['with', 'O'],\n",
       "  ['salt', 'B-FOOD'],\n",
       "  ['and', 'O'],\n",
       "  ['pepper', 'B-FOOD'],\n",
       "  ['.', 'O']]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preheat oven to 375 ° F . Place apples on large rimmed baking sheet ; toss with 3 tablespoons sugar , 2 tablespoons butter , and lemon juice . Roast until apples are tender , stirring occasionally , about 45 minutes . Transfer to large bowl . Stir in cherries , brown sugar , and vanilla . Cool completely . \n",
      "========\n",
      "Heat ghee in a large Dutch oven over medium heat . Season chicken with salt and pepper . Working in batches , cook chicken , skin side down , until golden brown ( do not turn ) , 8–10 minutes . Transfer to a plate . \n",
      "========\n",
      "6 . Chop the asparagus and leeks into 1-inch pieces . \n",
      "========\n",
      "Line baking sheet with paper towel . Heat oil in heavy large skillet over medium - high heat . Measure scant 1/4 cupful of mixture , shape into ball , and add to skillet . Using spatula , gently flatten ball to 1/3-inch - thick , 3-inch - diameter pancake . Repeat , forming 3 more pancakes . Fry until golden , about 3 minutes per side . Transfer pancakes to prepared baking sheet ; keep warm in oven . Repeat with remaining mixture for total of 8 pancakes . \n",
      "========\n",
      "Heat 1/2 cup oil in heavy large skillet over medium - high heat . Working in batches , fry crab cakes until brown , adding more oil to skillet as needed , about 4 minutes per side . Transfer 2 crab cakes to each of 12 plates . Serve , passing caper sauce alongside . \n",
      "========\n",
      "Spoon half of mousse into mold or soufflé dish and smooth top . Spoon roe evenly over mousse ( roe will not cover mousse completely ) and sprinkle evenly with dill . Spoon remaining mousse over dill , spreading mousse evenly ( being careful not to disturb roe and dill ) , and gently smooth surface . Chill mousse , covered , at least 12 hours and up to 2 days . \n",
      "========\n",
      "Combine 1/4 cup water , ginger , and sugar in heavy small saucepan . Stir over medium heat until sugar dissolves . Simmer until mixture is syrupy , about 5 minutes . Cool completely . Using electric mixer , beat cream in medium bowl until peaks form . Fold in ginger mixture . ( Can be made 4 hours ahead . Cover and chill . ) \n",
      "========\n",
      "In a cocktail shaker , combine gin , Chambord , cranberry juice and egg white , shake the drink vigorously , and strain it into a chilled cocktail glass . \n",
      "========\n",
      "Keep refrigerated at all times . You may prepare these custards a day or two in advance , but do n't keep them more than 3 days total . \n",
      "========\n",
      "Add potatoes to pot and cook , partially covered , until potatoes are fork - tender , chicken is falling off the bone , and liquid is thick enough to coat a spoon , 30–45 minutes . Remove skin and bones from chicken , if desired , and return meat to pot ; season stew with salt and pepper . \n",
      "========\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    text = \"\"\n",
    "    for token in example:\n",
    "\n",
    "        text += (token[0] + \" \")\n",
    "        \n",
    "    print(text)\n",
    "    print(\"========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:food] *",
   "language": "python",
   "name": "conda-env-food-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
