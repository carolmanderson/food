{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import ast\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from food_tools.training.dataset_utils import tokens_to_indices, correct_BIO_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_displacy(tokens, labels):\n",
    "    text = \"\"\n",
    "    start = 0\n",
    "    ents = []\n",
    "    curr_label = \"\"\n",
    "    new_ent = {}\n",
    "    for token, label in zip(tokens, labels):\n",
    "        text += token + \" \"\n",
    "        end = start + len(token)\n",
    "        if label.startswith(\"B-\"):\n",
    "            if new_ent:\n",
    "                ents.append(new_ent)\n",
    "            curr_label = label[2:]\n",
    "            new_ent = {\"start\": start, \"end\": end,\n",
    "                       \"label\": curr_label}\n",
    "        elif label.startswith(\"I-\"):\n",
    "            assert label[2:] == curr_label\n",
    "            new_ent['end'] = end\n",
    "        elif label == \"O\":\n",
    "            if new_ent:\n",
    "                ents.append(new_ent)\n",
    "                new_ent = {}\n",
    "        else:\n",
    "            raise Exception(\"Found non-BIO label {}!\".format(label))\n",
    "        start += len(token) + 1\n",
    "    if new_ent:\n",
    "        ents.append(new_ent)\n",
    "    doc = {\"text\": text,\n",
    "           \"ents\": ents,\n",
    "           \"title\": None}\n",
    "    return doc\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    https://github.com/tensorflow/tensorflow/issues/14356\n",
    "    https://github.com/tensorflow/tensorflow/issues/28287\n",
    "    \"\"\"\n",
    "    session = tf.Session(graph=tf.Graph())\n",
    "    with session.graph.as_default():\n",
    "        K.set_session(session)\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "        loaded_model.summary()\n",
    "    return loaded_model, session\n",
    "\n",
    "\n",
    "def load_mappings(filepath):\n",
    "    return pickle.load(open(filepath, \"rb\"))\n",
    "\n",
    "\n",
    "def load_sentencizer_and_tokenizer():\n",
    "    nlp = English()\n",
    "    sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "    nlp.add_pipe(sentencizer)\n",
    "    tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "    return nlp, tokenizer\n",
    "\n",
    "\n",
    "def form_matrix(tokens):\n",
    "    tokens = np.expand_dims(tokens, axis=0)\n",
    "    return np.array(tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Carol/anaconda/envs/food/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/Carol/anaconda/envs/food/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/Carol/anaconda/envs/food/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/Carol/anaconda/envs/food/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/Carol/anaconda/envs/food/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/Carol/anaconda/envs/food/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "token_input (InputLayer)     [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "word_embeddings (Embedding)  (None, None, 100)         40000500  \n",
      "_________________________________________________________________\n",
      "BiLSTM (Bidirectional)       (None, None, 200)         160800    \n",
      "_________________________________________________________________\n",
      "output_softmax (TimeDistribu (None, None, 3)           603       \n",
      "=================================================================\n",
      "Total params: 40,161,903\n",
      "Trainable params: 40,161,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model = \"/Users/Carol/Google Drive/nlp_data/output/20200503_16_50_50/20200503_16_50_50_food_ner_epoch_3_dev_f1_0.9867637173043644.h5\"\n",
    "\n",
    "saved_mappings = \"/Users/Carol/Google Drive/nlp_data/output/20200503_16_50_50/20200503_16_50_50_food_ner_mappings.pkl\"\n",
    "\n",
    "model, session = load_model(saved_model)\n",
    "mappings = load_mappings(saved_mappings)\n",
    "index_to_label = {v: k for k, v in mappings['label_to_index'].items()}\n",
    "token_to_index = mappings['token_to_index']\n",
    "sentencizer, tokenizer  = load_sentencizer_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"Heat garlic and rosemary with oil. Drizzle oil over dip and serve with \" \\\n",
    "                    \"vegetables.\"\n",
    "text = \"Combine pineapple, banana, cream of coconut, rolled \" \\\n",
    "                \"oats, quick-cooking oats, baking powder, mint, \" \\\n",
    "                \"chia seeds, and poppy seeds in a blender; blend until \" \\\n",
    "                \"smooth. Pour into 2 mugs.\"\n",
    "\n",
    "\n",
    "\n",
    "sents = sentencizer(text)\n",
    "all_tokens = []\n",
    "for sent in sents.sents:\n",
    "    tokens = tokenizer(sent.text)\n",
    "    all_tokens.append([t.text for t in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_food_terms(tokens, labels):\n",
    "    # get a list of food terms from NER prediction for classifier\n",
    "    text = \"\"\n",
    "    start = 0\n",
    "    ents = []\n",
    "    curr_label = \"\"\n",
    "    new_ent = {}\n",
    "    for token, label in zip(tokens, labels):\n",
    "        text += token + \" \"\n",
    "        end = start + len(token)\n",
    "        if label.startswith(\"B-\"):\n",
    "            if new_ent:\n",
    "                new_ent['text'] = text[new_ent['start']:new_ent['end']]\n",
    "                ents.append(new_ent)\n",
    "            curr_label = label[2:]\n",
    "            new_ent = {\"start\": start, \"end\": end,\n",
    "                       \"label\": curr_label}\n",
    "        elif label.startswith(\"I-\"):\n",
    "            assert label[2:] == curr_label\n",
    "            new_ent['end'] = end\n",
    "        elif label == \"O\":\n",
    "            if new_ent:\n",
    "                new_ent['text'] = text[new_ent['start']:new_ent['end']]\n",
    "                ents.append(new_ent)\n",
    "                new_ent = {}\n",
    "        else:\n",
    "            raise Exception(\"Found non-BIO label {}!\".format(label))\n",
    "        start += len(token) + 1\n",
    "    if new_ent:\n",
    "        new_ent['text'] = text[new_ent['start']:new_ent['end']]\n",
    "        ents.append(new_ent)\n",
    "    return ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doc = None   # collects entity results from all sentences\n",
    "all_terms = []   # collects food terms from all sentences\n",
    "with session.graph.as_default():\n",
    "    K.set_session(session)\n",
    "    for tokens in all_tokens:\n",
    "        token_indices = tokens_to_indices(tokens, token_to_index)\n",
    "        preds = model.predict([tokens_to_indices(tokens, token_to_index)])\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "        labels = [index_to_label[ind[0]] for ind in preds]\n",
    "        labels = correct_BIO_encodings(labels)\n",
    "        \n",
    "        terms = [term['text'] for term in extract_food_terms(tokens, labels)]\n",
    "        all_terms.extend(terms)\n",
    "        doc = output_to_displacy(tokens, labels)\n",
    "        if not final_doc:  # first sentence\n",
    "            final_doc = doc\n",
    "            continue\n",
    "        shift = len(final_doc['text'])\n",
    "        for ent in doc['ents']:\n",
    "            ent['start'] += shift\n",
    "            ent['end'] += shift\n",
    "            final_doc['ents'].append(ent)\n",
    "        final_doc['text'] += doc['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pineapple',\n",
       " 'banana',\n",
       " 'cream',\n",
       " 'coconut',\n",
       " 'oats',\n",
       " '-',\n",
       " 'oats',\n",
       " 'powder',\n",
       " 'mint',\n",
       " 'chia seeds',\n",
       " 'poppy seeds']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Combine pineapple , banana , cream of coconut , rolled oats , quick - cooking oats , baking powder , mint , chia seeds , and poppy seeds in a blender ; blend until smooth . Pour into 2 mugs . ',\n",
       " 'ents': [{'start': 8, 'end': 17, 'label': 'FOOD'},\n",
       "  {'start': 20, 'end': 26, 'label': 'FOOD'},\n",
       "  {'start': 29, 'end': 34, 'label': 'FOOD'},\n",
       "  {'start': 38, 'end': 45, 'label': 'FOOD'},\n",
       "  {'start': 55, 'end': 59, 'label': 'FOOD'},\n",
       "  {'start': 68, 'end': 69, 'label': 'FOOD'},\n",
       "  {'start': 78, 'end': 82, 'label': 'FOOD'},\n",
       "  {'start': 92, 'end': 98, 'label': 'FOOD'},\n",
       "  {'start': 101, 'end': 105, 'label': 'FOOD'},\n",
       "  {'start': 108, 'end': 118, 'label': 'FOOD'},\n",
       "  {'start': 125, 'end': 136, 'label': 'FOOD'}],\n",
       " 'title': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Combine \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pineapple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    banana\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cream\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " of \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    coconut\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , rolled \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    oats\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , quick \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    -\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " cooking \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    oats\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , baking \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    powder\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mint\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chia seeds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " , and \n",
       "<mark class=\"entity\" style=\"background: #87CEEB; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    poppy seeds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " in a blender ; blend until smooth . Pour into 2 mugs . </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {\"FOOD\": \"#87CEEB\"}\n",
    "options = {\"ents\": [\"FOOD\"], \"colors\": colors}\n",
    "displacy.render(final_doc, style=\"ent\", options={\"colors\":colors},\n",
    "                       manual=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Carol/anaconda/envs/food/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# load sklearn count vectorizer\n",
    "def get_tokens(input_cell):\n",
    "    return ast.literal_eval(input_cell)\n",
    "\n",
    "vect_file = \"/Users/Carol/Google Drive/nlp_data/models/20200613_vectorizer.p\"\n",
    "vectorizer = pickle.load(open(vect_file, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier models\n",
    "vegan_model_file = \"/Users/Carol/Google Drive/nlp_data/models/20200613_vegan.p\"\n",
    "vegan_model = pickle.load(open(vegan_model_file, \"rb\"))\n",
    "\n",
    "kosher_model_file = \"/Users/Carol/Google Drive/nlp_data/models/20200613_kosher.p\"\n",
    "kosher_model = pickle.load(open(kosher_model_file, \"rb\"))\n",
    "\n",
    "gf_model_file = \"/Users/Carol/Google Drive/nlp_data/models/20200613_gluten_free.p\"\n",
    "gf_model = pickle.load(open(gf_model_file, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.transform([str(all_terms)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan_prob = vegan_model.predict_proba(features)[0][1]\n",
    "kosher_prob = kosher_model.predict_proba(features)[0][1]\n",
    "gf_prob = gf_model.predict_proba(features)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052471418"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85738266"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kosher_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891858"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(gf_prob, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(100*kosher_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:food] *",
   "language": "python",
   "name": "conda-env-food-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
