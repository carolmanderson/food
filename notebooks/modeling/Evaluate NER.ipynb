{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import subprocess\n",
    "sys.path.append(\"../..\")\n",
    "from src.training.dataset_utils import read_conll_file, examples_to_indices\n",
    "from src.training.train_utils import evaluate_ner, form_ner_pred_matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/Carol/Google Drive/\"\n",
    "dev_file = os.path.join(base_path, \"nlp_data/recipe_data/20200523_food_gold_dev.conll\")\n",
    "model_file = \"/Users/Carol/Google Drive/nlp_data/output/20200523_22_06_28/20200523_22_06_28_food_ner_epoch_5_dev_f1_0.9851520816163143.h5\"\n",
    "mappings_file = \"/Users/Carol/Google Drive/nlp_data/output/20200523_22_06_28/20200523_22_06_28_food_ner_mappings.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pickle.load(open(mappings_file, \"rb\"))\n",
    "label_to_index = mappings['label_to_index']\n",
    "token_to_index = mappings['token_to_index']\n",
    "index_to_label = {v:k for k,v in label_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = read_conll_file(dev_file)\n",
    "dev_sentences = examples_to_indices(dev_dataset, label_to_index, token_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mappings = list(index_to_label.items())\n",
    "label_mappings.sort()\n",
    "label_strings = [x[1] for x in label_mappings]\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for sent in dev_sentences:\n",
    "    preds = model.predict_on_batch(form_ner_pred_matrix(sent['tokens']))\n",
    "    y_pred.extend(np.argmax(preds, axis=-1)[0])\n",
    "    y_true.extend(sent['labels'])\n",
    "metrics = classification_report(y_true, y_pred, target_names = label_strings,\n",
    "                                output_dict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      I-FOOD       0.93      0.86      0.89       278\n",
      "           O       0.99      0.99      0.99      9464\n",
      "      B-FOOD       0.95      0.94      0.95      1175\n",
      "\n",
      "    accuracy                           0.99     10917\n",
      "   macro avg       0.96      0.93      0.94     10917\n",
      "weighted avg       0.99      0.99      0.99     10917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# token-level metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to conll format for use of conll perl script to calculate entity-level metrics\n",
    "outfile = \"/Users/Carol/Google Drive/nlp_data/output/20200523_22_06_28/dev_conll.txt\"\n",
    "with open(outfile, \"w\") as out:\n",
    "    ctr = 0\n",
    "    for doc in dev_sentences:\n",
    "        for token in doc['raw_tokens']:\n",
    "            out.write(f\"{token} {index_to_label[y_true[ctr]]} {index_to_label[y_pred[ctr]]}\\n\")\n",
    "            ctr += 1\n",
    "        out.write(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = \"/Users/Carol/Google Drive/nlp_data/output/20200523_22_06_28/dev_conll.txt\"\n",
    "outfile = '/Users/Carol/Google Drive/nlp_data/output/20200523_22_06_28/eval.txt'\n",
    "conlleval_script_path = \"/Users/Carol/Dropbox/repos/food/src/evaluation\"\n",
    "os.chdir(conlleval_script_path)\n",
    "cmd = \"perl conlleval.pl < {} > {}\".format(json.dumps(infile), json.dumps(outfile))\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
